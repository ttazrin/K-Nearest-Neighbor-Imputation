DATA
The dataset that was collected from Kaggle [1], is a representation of weather. It contains a year wide weather report of temperature, humidity and the condition of 	a particular area, where temperature and humidity are continuous values and 	summary of the 	weather is a categorical value. Hence, there are a total of 3 features with 150 instances chosen from the original dataset at random. The dataset initially doesn’t have any missing values. The temperature value range from 5-20 (*C) approximately, and the humidity 	value have a range of 0 to 1.

METHODS
Imputation Methods
Three methods were used, one at a time, to perform imputation, 1NN, KNN, and Weighted KNN.

Nearest Neighbor
For 1NN, the distance of the other features of missing value instance was calculated from other complete instances and the nearest neighbor, that is, the instance having the smallest distance between features from the missing value was considered for imputation.

K Nearest Neighbor
The KNN method, however, computes the imputation using k smallest distances. In this case, k smallest number of distances of the missing value instance to complete cases were calculated and for categorical, the distance that occurs most was considered as imputed value (the mode) and for numerical features, the k value’s instances were averaged to find the imputed value. In the program, the value of k was considered to be 10. Since K values are being considered for making the decision for imputation, the model becomes more biased than 1NN.

Weighted K Nearest Neighbor
Weighted KNN calculates the distance of each instances from the particular instance, then assigns a weight to each class, in order to predict the class of missing value more accurately. The weight is calculated by inversing the distance of each instance and dividing it by the sum of all inversed distance. The class having the highest weight is then used for imputation.

Distance Measures

Euclidean Distance, Cosine Distance and Hamming Distance were used to calculate the distances between two features of an instance. For continuous features (Temperature & Humidity), Euclidean distance and Cosine Distance was used, and for categorical (Summary) hamming distance was used.

Euclidean Distance
Euclidean distance measures the distance between two points using the following formula:
Distance((x1,y1),(x2,y2)) = √((x2 – x1)² + (y2 – y1)²)	[2]
Where (x,y) represents each instances.

Cosine Distance
Cosine Distance measures the similarity between two instances by measuring the cosine angle between them. The cosine distance is calculated using [3]
Where a and b are two vectors of two instances.

Hamming Distance
Hamming Distance was used to calculate the categorical distance between two instances. It was calculated such that when two categories are not similar, the distance between them will be 1, if they are similar, distance will be 0. This approach was used because assigning different numerical distance values to difference between each category might give us a wrong imputation result. So a distance value of 1 is used to denote difference between the categories.


Feature Scaling

Since values of the features in dataset varies greatly, with temperature ranging from ~ 5-20 and humidity ranging from 0-1, the distance values might not be calculated properly as higher values can dominate the result. To avoid that, the features are all scaled within a range, reducing the deviation, so that all the values have the same effect on the result. Feature scaling was done using two methods: Min Max Scaling and Z Score Normalization.

Min Max Scaling
The min max scaling normalizes the value using standard normalization formula
Xnorm=(X−Xmin)/(Xmax−Xmin)	[4]
Where X represents each feature.
To calculate the min max normalization of provided dataset, sklearn library was used.

Z Score Normalization
Z Score Normalization also known as standardization, follows the properties of normal distribution with mean =0 and standard deviation =1. In order to calculate Z Score Normalization of the features, the following formula is used:
Z = (x−μ)/σ	[4]
Where x is the feature, μ is the mean and σ is the standard deviation.

Accuracy Measure

Numerical Accuracy
In order to calculate the accuracy of imputed values of numerical features (temperature and humidity), the following formula was used:
Accuracy = (1-(∑difference between imputed and original value)/(∑original value))*100	
The sum of difference between the original and imputed value for all missing value index was calculated first and subtracted from one in order to get the accuracy of imputation. The value was then multiplied by 100 to get the percentage of accuracy.


Categorical Accuracy
To calculate the categorical accuracy, the ratio of number of imputed values that matches the original value was calculated so find the ratio of correctly imputed result. It was then multiplied by 100 to get the percentage of accuracy. The formula goes as follows:
Accuracy = ((number of imputed values that matched original values)/█(total number of missing values@))*100


References:
[1] https://www.kaggle.com/muthuj7/weather-dataset
[2] http://rosalind.info/glossary/euclidean-distance/
[3] https://www.machinelearningplus.com/nlp/cosine-similarity/
[4] https://sebastianraschka.com/Articles/2014_about_feature_scaling.html
